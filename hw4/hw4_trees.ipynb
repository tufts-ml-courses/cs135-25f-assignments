{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW4 Trees and Forests\n",
    "\n",
    "Official instructions:\n",
    "\n",
    "https://www.cs.tufts.edu/cs/135/2025f/hw4.html\n",
    "\n",
    "This is the *starter code* notebook for Problem 2 specifically, looking at sentiment classification using bag-of-words features of product reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn.tree\n",
    "import sklearn.linear_model\n",
    "import sklearn.metrics\n",
    "import sklearn.ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the starter code\n",
    "from pretty_print_sklearn_tree import pretty_print_sklearn_tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting utils\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.style.use('seaborn-v0_8') # pretty matplotlib plots\n",
    "\n",
    "import seaborn as sns\n",
    "sns.set('notebook', font_scale=1.25, style='whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load all data from train/valid/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO fix to path on your local system\n",
    "DATA_DIR = os.path.join(\"data_product_reviews/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training data\n",
      "x_tr_NF.shape: (6346, 7729)\n",
      "y_tr_N.shape : (6346,)\n",
      "mean(y_tr_N) : 0.500\n"
     ]
    }
   ],
   "source": [
    "x_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'x_train.csv.zip'))\n",
    "y_tr_df = pd.read_csv(os.path.join(DATA_DIR, 'y_train.csv'))\n",
    "x_tr_NF = np.minimum(x_tr_df.values, 1.0).copy()\n",
    "y_tr_N = y_tr_df.values[:,0].copy()\n",
    "\n",
    "print(\"Training data\")\n",
    "print(\"x_tr_NF.shape: %s\" % str(x_tr_NF.shape))\n",
    "print(\"y_tr_N.shape : %s\" % str(y_tr_N.shape))\n",
    "print(\"mean(y_tr_N) : %.3f\" % np.mean(y_tr_N))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation data\n",
      "x_va_TF.shape: (792, 7729)\n",
      "y_va_T.shape : (792,)\n",
      "mean(y_va_T) : 0.490\n"
     ]
    }
   ],
   "source": [
    "x_va_df = pd.read_csv(os.path.join(DATA_DIR, 'x_valid.csv.zip'))\n",
    "y_va_df = pd.read_csv(os.path.join(DATA_DIR, 'y_valid.csv'))\n",
    "\n",
    "x_va_TF = np.minimum(x_va_df.values, 1.0).copy()\n",
    "y_va_T = y_va_df.values[:,0].copy()\n",
    "\n",
    "print(\"Validation data\")\n",
    "print(\"x_va_TF.shape: %s\" % str(x_va_TF.shape))\n",
    "print(\"y_va_T.shape : %s\" % str(y_va_T.shape))\n",
    "print(\"mean(y_va_T) : %.3f\" % np.mean(y_va_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Heldout Test data\n",
      "x_te_TF.shape: (793, 7729)\n",
      "y_te_T.shape : (793,)\n",
      "mean(y_te_T) : 0.515\n"
     ]
    }
   ],
   "source": [
    "x_te_df = pd.read_csv(os.path.join(DATA_DIR, 'x_test.csv.zip'))\n",
    "y_te_df = pd.read_csv(os.path.join(DATA_DIR, 'y_test.csv'))\n",
    "\n",
    "x_te_TF = np.minimum(x_te_df.values, 1.0).copy()\n",
    "y_te_T = y_te_df.values[:,0].copy()\n",
    "\n",
    "print(\"Heldout Test data\")\n",
    "print(\"x_te_TF.shape: %s\" % str(x_te_TF.shape))\n",
    "print(\"y_te_T.shape : %s\" % str(y_te_T.shape))\n",
    "print(\"mean(y_te_T) : %.3f\" % np.mean(y_te_T))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load vocabulary as a list of strings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total vocab size 7729\n"
     ]
    }
   ],
   "source": [
    "vocab_list = x_tr_df.columns.tolist()\n",
    "\n",
    "print(\"total vocab size\", len(vocab_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "good\n",
      "great\n",
      "time\n",
      "book\n",
      "don't\n",
      "work\n",
      "i_have\n",
      "read\n",
      "...\n",
      "never_get\n",
      "i'd_like\n",
      "loves_it\n",
      "an_author\n",
      "nomin\n",
      "could_give\n",
      "bad_but\n",
      "gap\n"
     ]
    }
   ],
   "source": [
    "for word in vocab_list[:8]:\n",
    "    print(word)\n",
    "print(\"...\")\n",
    "for word in vocab_list[-8:]:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pack training and validation sets into big arrays (so we can use sklearn's hyperparameter search tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xall_LF = np.vstack([x_tr_NF, x_va_TF])\n",
    "yall_L = np.hstack([y_tr_N, y_va_T])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_indicators_L = np.hstack([\n",
    "    -1 * np.ones(y_tr_N.size), # -1 means never include this example in any test split\n",
    "    0  * np.ones(y_va_T.size), #  0 means include in the first test split (we count starting at 0 in python)\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create splitter object using Predefined Split\n",
    "# Will be used later by all hyperparameter searches\n",
    "\n",
    "my_splitter = sklearn.model_selection.PredefinedSplit(valid_indicators_L)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tip: Perform fixed validation using GridsearchCV by passing a predefined split**\n",
    "\n",
    "Although `GridsearchCV` is mostly used for cross validation (as the name implies), we can still have it perform fixed validation by passing a predefined split as the `cv` parameter when calling it. And a `PredefinedSplit` object is how we construct a predefined split. We can pass the desired splitting scheme to `PredefinedSplit` to control how the data is split into train/validation data. We will illustrate this using a simple dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_LF = np.asarray([[1, 3],\n",
    "                  [4, 4],\n",
    "                  [8, 2],\n",
    "                  [4, 3],\n",
    "                  [7, 7]])\n",
    "Y_L = np.asarray([4, 8, 10, 7, 14])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's say that we want to use the examples indexed at 0, 1, and 2 as the training set and the examples indexed at 3 and 4 as the validation set. We can specify this using a `PredefinedSplit`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "splitter = sklearn.model_selection.PredefinedSplit(test_fold=[-1, -1, -1, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, `-1` means to never include the example at this position in any validation fold (i.e. only use them for training), and `0` means to use the example at this position in the number 0 validation fold. But since we are doing fixed validation, there is only one validation fold (number 0).\n",
    "\n",
    "By passing the defined `splitter` as the `cv` parameter into sklearn's `GridsearchCV` object, we can ask it to do fixed validation using the split we defined, instead of the default cross validation.\n",
    "\n",
    "In hyperparameter searching, `GridsearchCV` will train the models using the examples corresponding to `-1`s in `test_fold` and validate using the examples corresponding to `0`s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training indices: [0 1 2]\n",
      "Validation indices: [3 4]\n"
     ]
    }
   ],
   "source": [
    "for _, (train_index, test_index) in enumerate(splitter.split()):\n",
    "    print(f\"Training indices: {train_index}\")\n",
    "    print(f\"Validation indices: {test_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For more details, see the `PredefinedSplit` doc [here](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.PredefinedSplit.html). \n",
    "\n",
    "Now, utilize the `my_splitter` that we defined above for our sentiment classification task to perform fixed validation using `GridsearchCV` in the following problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Trees\n",
    "\n",
    "## Step 1A: Train a simple tree with depth 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='entropy', \n",
    "    max_depth=3,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1, \n",
    "    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Fit the tree** \n",
    "\n",
    "**TODO Train on the training set** in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO\n",
    "# simple_tree.fit(FIXME, FIXME)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Figure 1: Print Tree** \n",
    "\n",
    "Use a helper function from the starter code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO \n",
    "# call pretty_print_sklearn_tree on simple_tree, providing feature_names=vocab_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1B : Find best Decision Tree with grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the default predictor\n",
    "# Any hyperparameters here may be overridden by the hyperparameter grid\n",
    "\n",
    "base_tree = sklearn.tree.DecisionTreeClassifier(\n",
    "    criterion='entropy',\n",
    "    max_depth=8,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1,\n",
    "    random_state=101,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_hyperparameter_grid_by_name = dict(\n",
    "    max_depth=[2, 8, 32, 128],\n",
    "    min_samples_leaf=[1, 3, 9],\n",
    "    random_state = [101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Build the Grid Search** in the next coding cell\n",
    "\n",
    "Follow the 1B instructions carefully:\n",
    "\n",
    "* Set `scoring='balanced_accuracy'`, since our target metric is balanced accuracy\n",
    "* Set `cv=my_splitter` (as in starter code), so you can use the predefined split we defined earlier.\n",
    "* Set `return_train_score=True`, since we want training set scores as well as valdiation set scores (which will be called 'test' by the searcher)\n",
    "* Set `refit=False`, because we only want fits on `x_tr_NF`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_grid_searcher = None # TODO fixme use GridSearchCV, and point it to your PredefinedSplit my_splitter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time_sec = time.time()\n",
    "# TODO call me: tree_grid_searcher.fit(xall_LF, yall_L)\n",
    "elapsed_time_sec = time.time() - start_time_sec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataframe of results\n",
    "\n",
    "Move the results of grid search into a nice pandas data frame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    # Will execute if you called fit on tree_grid_searcher succesfully\n",
    "    tree_search_results_df = pd.DataFrame(tree_grid_searcher.cv_results_).copy()\n",
    "    print(\"Grid search of %3d configurations done after %6.1f sec\" % (\n",
    "        tree_search_results_df.shape[0], elapsed_time_sec))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display search results\n",
    "\n",
    "This block will make a pretty printed table of the results of your grid search"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if hasattr(tree_grid_searcher, 'cv_results_'):\n",
    "    pd.set_option('display.precision', 4)\n",
    "    tree_keys = ['param_max_depth', 'param_min_samples_leaf']\n",
    "    tree_search_results_df.sort_values(tree_keys, inplace=True)\n",
    "    tree_search_results_df[tree_keys + ['mean_train_score', 'mean_test_score', 'rank_test_score', 'mean_fit_time']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Printing a dict of the best hyperparameters\n",
      "AttributeError happens if you did not complete earlier 'Do the search' todo\n"
     ]
    }
   ],
   "source": [
    "print(\"Printing a dict of the best hyperparameters\")\n",
    "try:\n",
    "    print(tree_grid_searcher.best_params_)\n",
    "except AttributeError:\n",
    "    print(\"AttributeError happens if you did not complete earlier 'Do the search' todo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best decision tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TODO Build the Best Tree on the training set** in the next coding cell\n",
    "\n",
    "This is necessary so you have the specific best performing tree in your workspace.\n",
    "\n",
    "Although you fit many trees in the search, they were not stored, so we need to recreate the best one.\n",
    "\n",
    "Hint: Just feed the best hyperparameters as keyword args to construct the tree and fit it to the training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=101)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;&nbsp;DecisionTreeClassifier<a class=\"sk-estimator-doc-link fitted\" rel=\"noreferrer\" target=\"_blank\" href=\"https://scikit-learn.org/1.5/modules/generated/sklearn.tree.DecisionTreeClassifier.html\">?<span>Documentation for DecisionTreeClassifier</span></a><span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>DecisionTreeClassifier(criterion=&#x27;entropy&#x27;, max_depth=8, random_state=101)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "DecisionTreeClassifier(criterion='entropy', max_depth=8, random_state=101)"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_tree = base_tree # TODO call set_params using the best_params_ found by your searcher\n",
    "best_tree.fit(x_tr_NF, y_tr_N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interpret the best decision tree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The binary tree structure has 139 nodes.\n",
      "- depth   0 has    1 nodes, of which    0 are leaves\n",
      "- depth   1 has    2 nodes, of which    0 are leaves\n",
      "- depth   2 has    4 nodes, of which    0 are leaves\n",
      "- depth   3 has    8 nodes, of which    1 are leaves\n",
      "- depth   4 has   14 nodes, of which    4 are leaves\n",
      "- depth   5 has   20 nodes, of which    6 are leaves\n",
      "- depth   6 has   28 nodes, of which   12 are leaves\n",
      "- depth   7 has   32 nodes, of which   17 are leaves\n",
      "- depth   8 has   30 nodes, of which   30 are leaves\n",
      "The decision tree:  (Note: Y = 'yes' to above question; N = 'no')\n",
      "Decision: X['great'] <= 0.50?\n",
      "  Y Decision: X['excel'] <= 0.50?\n",
      "    Y Decision: X['waste'] <= 0.50?\n",
      "      Y Decision: X['disappoint'] <= 0.50?\n",
      "        Y Decision: X['love'] <= 0.50?\n",
      "          Y Decision: X['easy_to'] <= 0.50?\n",
      "            Y Decision: X['bad'] <= 0.50?\n",
      "              Y Decision: X['poor'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.443 (2835 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.092 (152 total training examples)\n",
      "              N Decision: X['perfect'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.124 (299 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.727 (11 total training examples)\n",
      "            N Decision: X['humor'] <= 0.50?\n",
      "              Y Decision: X['custom'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.889 (135 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.250 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "          N Decision: X['worst'] <= 0.50?\n",
      "            Y Decision: X['didn't'] <= 0.50?\n",
      "              Y Decision: X['poor'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.765 (357 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.125 (8 total training examples)\n",
      "              N Decision: X['if_you'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.586 (29 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.083 (12 total training examples)\n",
      "            N Decision: X['i_found'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (10 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (2 total training examples)\n",
      "        N Decision: X['be_disappointed'] <= 0.50?\n",
      "          Y Decision: X['and_never'] <= 0.50?\n",
      "            Y Decision: X['televis'] <= 0.50?\n",
      "              Y Decision: X['story_and'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.051 (311 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.750 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "          N Decision: X['meant'] <= 0.50?\n",
      "            Y Decision: X['this_one'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 1.000 (16 total training examples)\n",
      "              N Decision: X['there_was'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.000 (2 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (2 total training examples)\n",
      "      N Decision: X['contain'] <= 0.50?\n",
      "        Y Decision: X['runs'] <= 0.50?\n",
      "          Y Decision: X['sales'] <= 0.50?\n",
      "            Y Decision: X['<num>_<fraction>'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (203 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 1.000 (2 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "    N Decision: X['disappoint'] <= 0.50?\n",
      "      Y Decision: X['imagin'] <= 0.50?\n",
      "        Y Decision: X['stuck'] <= 0.50?\n",
      "          Y Decision: X['publish'] <= 0.50?\n",
      "            Y Decision: X['me_but'] <= 0.50?\n",
      "              Y Decision: X['items'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.950 (261 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (2 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.000 (2 total training examples)\n",
      "            N Decision: X['on_your'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 0.000 (3 total training examples)\n",
      "        N Decision: X['reward'] <= 0.50?\n",
      "          Y Leaf: p(y=1 | this leaf) = 0.000 (4 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "      N Decision: X['the_quality'] <= 0.50?\n",
      "        Y Decision: X['special'] <= 0.50?\n",
      "          Y Decision: X['side'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 0.000 (8 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 1.000 (1 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 1.000 (2 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "  N Decision: X['return'] <= 0.50?\n",
      "    Y Decision: X['bad'] <= 0.50?\n",
      "      Y Decision: X['disappoint'] <= 0.50?\n",
      "        Y Decision: X['worst'] <= 0.50?\n",
      "          Y Decision: X['great_but'] <= 0.50?\n",
      "            Y Decision: X['love'] <= 0.50?\n",
      "              Y Decision: X['horribl'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.774 (1021 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.091 (11 total training examples)\n",
      "              N Decision: X['negat'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.930 (213 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.200 (5 total training examples)\n",
      "            N Decision: X['a_great'] <= 0.50?\n",
      "              Y Decision: X['cook'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.439 (41 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (6 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "          N Decision: X['real'] <= 0.50?\n",
      "            Y Decision: X['best_of'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 0.000 (21 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (2 total training examples)\n",
      "            N Decision: X['the_back'] <= 0.50?\n",
      "              Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 0.000 (1 total training examples)\n",
      "        N Decision: X['be_disappointed'] <= 0.50?\n",
      "          Y Decision: X['don't'] <= 0.50?\n",
      "            Y Decision: X['of_my'] <= 0.50?\n",
      "              Y Decision: X['for_me'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.327 (52 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 1.000 (4 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (13 total training examples)\n",
      "          N Decision: X['one_would'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (1 total training examples)\n",
      "      N Decision: X['is_really'] <= 0.50?\n",
      "        Y Decision: X['run'] <= 0.50?\n",
      "          Y Decision: X['place'] <= 0.50?\n",
      "            Y Decision: X['set_of'] <= 0.50?\n",
      "              Y Decision: X['when_i'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.385 (96 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (12 total training examples)\n",
      "              N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (11 total training examples)\n",
      "          N Decision: X['many_times'] <= 0.50?\n",
      "            Y Leaf: p(y=1 | this leaf) = 1.000 (9 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 0.000 (1 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (8 total training examples)\n",
      "    N Decision: X['in_all'] <= 0.50?\n",
      "      Y Decision: X['is_one'] <= 0.50?\n",
      "        Y Decision: X['suffer'] <= 0.50?\n",
      "          Y Decision: X['but_then'] <= 0.50?\n",
      "            Y Decision: X['made_in'] <= 0.50?\n",
      "              Y Decision: X['than_that'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 0.030 (67 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 1.000 (2 total training examples)\n",
      "              N Decision: X['spend'] <= 0.50?\n",
      "                Y Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "                N Leaf: p(y=1 | this leaf) = 0.000 (1 total training examples)\n",
      "            N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "          N Leaf: p(y=1 | this leaf) = 1.000 (3 total training examples)\n",
      "        N Leaf: p(y=1 | this leaf) = 1.000 (5 total training examples)\n",
      "      N Leaf: p(y=1 | this leaf) = 1.000 (7 total training examples)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "pretty_print_sklearn_tree(best_tree, feature_names=vocab_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random forests!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1C: Train a random forest with default settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "simple_forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='entropy',\n",
    "    max_features='sqrt',\n",
    "    max_depth=3,\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=2,\n",
    "    random_state=101)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fit the forest\n",
    "\n",
    "**TODO Train on the training set** in the next coding cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO FIXME call fit, like: `simple_forest.fit(None, None)`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1D: Best Random Forest via grid search\n",
    "\n",
    "Follow the instructions and using what you learn above to finish this step.\n",
    "\n",
    "This block might take 2-10 minutes. (Takes about 2 min on staff Macbook laptops from before 2020.)\n",
    "\n",
    "If yours runs significantly longer, try this out on Google Colab instead."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_forest = sklearn.ensemble.RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    criterion='entropy',\n",
    "    max_depth=16,\n",
    "    min_samples_split=2,\n",
    "    min_samples_leaf=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest_hyperparameter_grid_by_name = dict(\n",
    "    max_features=[3, 10, 33, 100, 333],\n",
    "    max_depth=[16, 32],\n",
    "    min_samples_leaf=[1],\n",
    "    n_estimators=[100],\n",
    "    random_state=[101],\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO construct a GridSearchCV object like you did above for a single tree\n",
    "# Make sure you point it to our predefined split\n",
    "\n",
    "forest_searcher = None "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Do the search!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build dataframe of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display search results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Build the best random forest using the best hyperparameters found\n",
    "\n",
    "This is necessary so you have the specific best performing forest in your workspace.\n",
    "\n",
    "Train *only* on training set (do not merge train and valid)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Hint: you can call balanced accuracy like this:\n",
    "\n",
    "ytrue_A = [1, 1, 1, 1, 1, 1, 0, 0, 0, 0]\n",
    "yhat_A  = [1, 1, 1, 1, 1, 1, 0, 0, 1, 1]\n",
    "\n",
    "# of the true 1s, we get them 100% correct\n",
    "# of the true 0s, we get them 50% correct\n",
    "# so the *class-balanced* accuracy = 0.5 * 100 + 0.5 * 50 = 75%\n",
    "\n",
    "sklearn.metrics.balanced_accuracy_score(ytrue_A, yhat_A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table 2: Comparison of methods on the bag-of-words to sentiment classification task.\n",
    "\n",
    "Remember, in your workspace, you should have the following models defined\n",
    "\n",
    "* `simple_tree`, from 1A\n",
    "* `best_tree`, from 1B\n",
    "* `simple_forest`, from 1C\n",
    "* `best_forest`, from 1D\n",
    "\n",
    "\n",
    "Please report **balanced accuracy** on the train, valid, and test sets, to 3 digits of precision\n",
    "\n",
    "**Sample Output** (Feel free to print all values and organize them by hand)\n",
    "\n",
    "|**method**|**max depth**|**num trees**|**train BAcc**|**valid BAcc**|**test BAcc**|\n",
    "|:-|:-:|:-:|:-:|:-:|:-:|\n",
    "|simple Tree\t| 1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best Tree\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|simple RandomForest\t|1 | 1 | 0.123\t|0.456\t|0.890|\n",
    "|best RandomForest\t|1 | 1 | 0.123\t|0.456\t|0.890|"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
